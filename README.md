# Text_Summarisation

With the exponential rise in scientific publications, researchers struggle to keep up with the vast volume of literature. The challenge lies in creating a state-of-the-art model that accurately summarizes research articles while preserving key insights and readability, enabling researchers to assimilate information swiftly. Scientific papers differ significantly from general text due to their structured frmat (Introduction, Methods, Results, Discussion, etc.), citation dependencies, and inclusion of figure/tables. Summarizing such documents requires handling domain-specific challenges, maintaining semantic coherence, and ensuring faithful knowledge retention. This competition challenges participants to develop a framework for summarizing research artciels, leveraging state-of-the-art approaches, preferably by using Large Language Models (LLMs) with an aim to develop a hybrid summarization model that surpasses existing benchmark models while maintaining computational efficiency.

An extractive-abstractive hybrid model that:

Summarized single and multi-document research papers
Handles long-document summarization constraints while maintaining efficiency
Participants will be provided with multiple research article datasets, including a proprietary dataset from IIEST Shibpur, CompScholar, and two publicly available benchmark datasets (PubMed and arXiv). The task is to develop an efficient text-based abstractive summarization model that generates concise, coherent, and relevant summaries while outperforming existing models. Participants must also compare their models against state-of-the-art summarization frameworks BART with supervised fine tuning. (e.g., SummRuNNer, Pointer-Generator, Discourse Aware, BERT, T5, BART, PEGASUS, GPT-4, Longformer, and LED), providing a detailed performance analysis with citations.
